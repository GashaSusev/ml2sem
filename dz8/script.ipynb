{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport random\nimport string\nfrom string import ascii_letters","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:41:03.407317Z","iopub.execute_input":"2025-06-22T21:41:03.408076Z","iopub.status.idle":"2025-06-22T21:41:07.447276Z","shell.execute_reply.started":"2025-06-22T21:41:03.408044Z","shell.execute_reply":"2025-06-22T21:41:07.446565Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"def caesar_cipher(text, shift):\n    alphabet_lower = string.ascii_lowercase + \" \"\n    alphabet_upper = string.ascii_uppercase\n    shifted_alphabet_lower = alphabet_lower[shift:] + alphabet_lower[:shift]\n    shifted_alphabet_upper = alphabet_upper[shift:] + alphabet_upper[:shift]\n    return \"\".join(\n        (\n            shifted_alphabet_lower[alphabet_lower.index(c)]\n            if c in alphabet_lower\n            else shifted_alphabet_upper[alphabet_upper.index(c)]\n        )\n        for c in text\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:41:07.448522Z","iopub.execute_input":"2025-06-22T21:41:07.448780Z","iopub.status.idle":"2025-06-22T21:41:07.454287Z","shell.execute_reply.started":"2025-06-22T21:41:07.448765Z","shell.execute_reply":"2025-06-22T21:41:07.453525Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"text = \"The quick brown fox jumps over the lazy dog. This sentence contains all the letters in the English alphabet. Artificial intelligence is transforming industries worldwide. Machine learning models require large datasets for training. The sun rises in the east and sets in the west. Python is a popular programming language for data science. History repeats itself, but each time the price goes up. Innovation distinguishes between a leader and a follower. The only way to do great work is to love what you do. Life is what happens when you are busy making other plans. Science is organized knowledge; wisdom is organized life. Water covers approximately 71% of the Earths surface. The human brain has about 86 billion neurons. Quantum computing promises to revolutionize cryptography. Renewable energy sources are critical for sustainability. The Internet of Things connects everyday devices to the cloud.Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nullam euismod odio at libero volutpat, id fermentum nisi finibus. Curabitur quis enim vel turpis malesuada tincidunt. Sed non neque ut erat aliquam rhoncus. Fusce in lectus id mi tempus aliquet.\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:41:07.455448Z","iopub.execute_input":"2025-06-22T21:41:07.455679Z","iopub.status.idle":"2025-06-22T21:41:07.470869Z","shell.execute_reply.started":"2025-06-22T21:41:07.455656Z","shell.execute_reply":"2025-06-22T21:41:07.470193Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"len(text)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:41:07.472559Z","iopub.execute_input":"2025-06-22T21:41:07.473005Z","iopub.status.idle":"2025-06-22T21:41:07.486300Z","shell.execute_reply.started":"2025-06-22T21:41:07.472979Z","shell.execute_reply":"2025-06-22T21:41:07.485677Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"1155"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"preprocessed_text = [simb for simb in text if simb in (ascii_letters + \" \")]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:41:07.487043Z","iopub.execute_input":"2025-06-22T21:41:07.487357Z","iopub.status.idle":"2025-06-22T21:41:07.498869Z","shell.execute_reply.started":"2025-06-22T21:41:07.487342Z","shell.execute_reply":"2025-06-22T21:41:07.498192Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"class RNN(nn.Module):\n    def __init__(self, input_size, hidden_size, output_size, num_layers=3):\n        super(RNN, self).__init__()\n        self.hidden_size = hidden_size\n        self.num_layers = num_layers\n        self.embedding = nn.Embedding(input_size, hidden_size)\n        self.rnn = nn.RNN(\n            hidden_size, hidden_size, num_layers=num_layers, batch_first=True\n        )\n        self.fc = nn.Linear(hidden_size, output_size)\n\n    def forward(self, x, hidden):\n        x = self.embedding(x)\n        out, hidden = self.rnn(x, hidden)\n        out = self.fc(out)\n        return out, hidden\n\n    def init_hidden(self, batch_size):\n        return torch.randn(self.num_layers, batch_size, self.hidden_size)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:41:07.499595Z","iopub.execute_input":"2025-06-22T21:41:07.499825Z","iopub.status.idle":"2025-06-22T21:41:07.512966Z","shell.execute_reply.started":"2025-06-22T21:41:07.499802Z","shell.execute_reply":"2025-06-22T21:41:07.512396Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"def prepare_data(num_samples, max_length):\n    X, y = [], []\n    alphabet = string.ascii_letters + \" \"\n\n    for _ in range(num_samples):\n        idx = random.randint(0, len(preprocessed_text) - 1)\n        length = random.randint(5, max_length)\n        text = \"\".join(\n            preprocessed_text[idx : min(idx + length, len(preprocessed_text))]\n        )\n        shift = 5\n\n        encrypted = caesar_cipher(text, shift)\n        x_seq = [alphabet.index(c) for c in encrypted]\n        y_seq = [alphabet.index(c) for c in text]\n\n        X.append(x_seq)\n        y.append(y_seq)\n\n    return X, y\n\ndef prepare_train(X, y, max_length):\n    X_padded = torch.zeros((len(X), max_length), dtype=torch.long)\n    y_padded = torch.zeros((len(y), max_length), dtype=torch.long)\n\n    for i, (x_seq, y_seq) in enumerate(zip(X, y)):\n        length = len(x_seq)\n        X_padded[i, :length] = torch.tensor(x_seq)\n        y_padded[i, :length] = torch.tensor(y_seq)\n\n    return X_padded, y_padded","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:41:07.513758Z","iopub.execute_input":"2025-06-22T21:41:07.514013Z","iopub.status.idle":"2025-06-22T21:41:07.529780Z","shell.execute_reply.started":"2025-06-22T21:41:07.513992Z","shell.execute_reply":"2025-06-22T21:41:07.529059Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"def train_model(model, X, y, epochs, batch_size, device):\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    model.train()\n    for epoch in range(epochs):\n        total_loss = 0\n        for i in range(0, len(X), batch_size):\n            batch_X = X[i : i + batch_size].to(device)\n            batch_y = y[i : i + batch_size].to(device)\n\n            hidden = model.init_hidden(batch_X.size(0)).to(device)\n            optimizer.zero_grad()\n            outputs, hidden = model(batch_X, hidden)\n\n            loss = criterion(outputs.view(-1, 53), batch_y.view(-1))\n\n            loss.backward()\n            optimizer.step()\n\n            total_loss += loss.item()\n\n        print(\n            f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss / (len(X) // batch_size):.4f}\"\n        )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:41:07.530503Z","iopub.execute_input":"2025-06-22T21:41:07.530691Z","iopub.status.idle":"2025-06-22T21:41:07.543940Z","shell.execute_reply.started":"2025-06-22T21:41:07.530677Z","shell.execute_reply":"2025-06-22T21:41:07.543239Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"n_samples = 100\nmax_len = 20\nhidden_size = 128\nepochs = 20\nbatch_size = 32\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)\n\nX, y = prepare_data(n_samples, max_len)\nX_tensor, y_tensor = prepare_train(X, y, max_len)\nX_tensor.size()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:43:48.995992Z","iopub.execute_input":"2025-06-22T21:43:48.996222Z","iopub.status.idle":"2025-06-22T21:43:49.007259Z","shell.execute_reply.started":"2025-06-22T21:43:48.996208Z","shell.execute_reply":"2025-06-22T21:43:49.006610Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"torch.Size([100, 20])"},"metadata":{}}],"execution_count":23},{"cell_type":"code","source":"model = RNN(\n    input_size=53, hidden_size=hidden_size, output_size=53, num_layers=5\n).to(device)\ntrain_model(model, X_tensor, y_tensor, epochs, batch_size, device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:41:29.788201Z","iopub.execute_input":"2025-06-22T21:41:29.788494Z","iopub.status.idle":"2025-06-22T21:41:33.222700Z","shell.execute_reply.started":"2025-06-22T21:41:29.788474Z","shell.execute_reply":"2025-06-22T21:41:33.221974Z"}},"outputs":[{"name":"stdout","text":"Epoch 1/20, Loss: 4.7002\nEpoch 2/20, Loss: 3.6164\nEpoch 3/20, Loss: 3.1977\nEpoch 4/20, Loss: 2.8406\nEpoch 5/20, Loss: 2.5721\nEpoch 6/20, Loss: 2.3378\nEpoch 7/20, Loss: 2.1393\nEpoch 8/20, Loss: 1.9438\nEpoch 9/20, Loss: 1.7482\nEpoch 10/20, Loss: 1.5839\nEpoch 11/20, Loss: 1.4108\nEpoch 12/20, Loss: 1.2638\nEpoch 13/20, Loss: 1.1154\nEpoch 14/20, Loss: 0.9918\nEpoch 15/20, Loss: 0.8708\nEpoch 16/20, Loss: 0.7674\nEpoch 17/20, Loss: 0.6684\nEpoch 18/20, Loss: 0.5813\nEpoch 19/20, Loss: 0.5120\nEpoch 20/20, Loss: 0.4391\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"def decrypt_text(model, encrypted_text, max_length, device):\n    alphabet = string.ascii_letters + \" \"\n    model.eval()\n\n    x_seq = [alphabet.index(c) for c in encrypted_text if c in alphabet]\n    x_tensor = torch.zeros((1, max_length), dtype=torch.long).to(device)\n    x_tensor[0, : len(x_seq)] = torch.tensor(x_seq)\n\n    with torch.no_grad():\n        hidden = model.init_hidden(1).to(device)\n        outputs, _ = model(x_tensor, hidden)\n        _, predicted = torch.max(outputs, dim=2)\n\n    decrypted = \"\".join(alphabet[idx] for idx in predicted[0][: len(x_seq)])\n    return decrypted","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:41:35.957685Z","iopub.execute_input":"2025-06-22T21:41:35.958044Z","iopub.status.idle":"2025-06-22T21:41:35.963445Z","shell.execute_reply.started":"2025-06-22T21:41:35.958024Z","shell.execute_reply":"2025-06-22T21:41:35.962723Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"test_text = \"test rnn infer\"\nshift = 5\nencrypted = caesar_cipher(test_text, shift)\nprint(f\"Оригинальный текст: {test_text}\")\nprint(f\"Зашифрованный текст: {encrypted}\")\ndecrypted = decrypt_text(model, encrypted, max_len, device)\nprint(f\"Дешифрованный текст: {decrypted}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T21:42:12.080077Z","iopub.execute_input":"2025-06-22T21:42:12.080345Z","iopub.status.idle":"2025-06-22T21:42:12.086693Z","shell.execute_reply.started":"2025-06-22T21:42:12.080326Z","shell.execute_reply":"2025-06-22T21:42:12.086134Z"}},"outputs":[{"name":"stdout","text":"Оригинальный текст: test rnn infer\nЗашифрованный текст: yjxyewssenskjw\nДешифрованный текст: test rnn inger\n","output_type":"stream"}],"execution_count":18}]}